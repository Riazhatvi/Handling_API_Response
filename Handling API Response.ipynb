{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Libraries:"
      ],
      "metadata": {
        "id": "35WZv-obcaNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "import pandas as pd\n",
        "import requests\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n"
      ],
      "metadata": {
        "id": "Gf-QNf8wnrWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection (Part 1):\n",
        "The script initiates the process of data collection from the Parliament API (api.parliament.uk/sparql/).\n",
        "A SPARQL query is formulated to fetch information about inquiries submitted by Members of Parliament (MPs) in the House of Commons from January 2023 to September 2023.\n",
        "The API is then queried using the requests.post method, and the response is stored.\n",
        "# Handling API Response (Part 1):\n",
        "The code checks if the API response status is 200 (OK), indicating a successful request.\n",
        "The JSON response is then processed to extract relevant information like MP details, constituencies, and inquiry texts.\n",
        "A Pandas DataFrame (mp_inquiries_df_part1) is created to organize the collected data."
      ],
      "metadata": {
        "id": "asLh8HVscLcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Collection from Parliament API\n",
        "sparql_query_part1 = \"\"\"\n",
        "SELECT ?mp ?constituency ?inquiryText\n",
        "WHERE {\n",
        "  ?mp a :MemberOfParliament;\n",
        "      :represents ?constituency;\n",
        "      :makesInquiry ?inquiry;\n",
        "      :inquiryDate ?date.\n",
        "  FILTER (?date >= \"2023-01-01\"^^xsd:date && ?date <= \"2023-09-30\"^^xsd:date)\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "api_url = \"https://api.parliament.uk/sparql\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/sparql-query\",\n",
        "    \"Accept\": \"application/json\",\n",
        "}\n",
        "params = {\n",
        "    \"query\": sparql_query_part1,  # Make sure the query is included here\n",
        "    \"format\": \"json\",\n",
        "}\n",
        "\n",
        "response_part1 = requests.post(api_url, headers=headers, params=params)\n",
        "\n",
        "if response_part1.status_code == 200:\n",
        "    data_part1 = response_part1.json()\n",
        "    mp_inquiries_data_part1 = []\n",
        "\n",
        "    for result in data_part1.get(\"results\", {}).get(\"bindings\", []):\n",
        "        mp = result.get(\"mp\", {}).get(\"value\", \"\")\n",
        "        constituency = result.get(\"constituency\", {}).get(\"value\", \"\")\n",
        "        inquiry_text = result.get(\"inquiryText\", {}).get(\"value\", \"\")\n",
        "\n",
        "        mp_inquiries_data_part1.append({\n",
        "            \"MP\": mp,\n",
        "            \"Constituency\": constituency,\n",
        "            \"InquiryText\": inquiry_text,\n",
        "        })\n",
        "\n",
        "    mp_inquiries_df_part1 = pd.DataFrame(mp_inquiries_data_part1)\n",
        "\n",
        "    # Continue with the rest of the code (Region Categorization)\n",
        "\n",
        "    def map_constituency_to_region(constituency):\n",
        "        if \"Scotland\" in constituency:\n",
        "            return \"Scotland\"\n",
        "        elif \"Northern Ireland\" in constituency:\n",
        "            return \"Northern Ireland\"\n",
        "        else:\n",
        "            return \"England\"\n",
        "\n",
        "    mp_inquiries_df_part1['Region'] = mp_inquiries_df_part1['Constituency'].apply(map_constituency_to_region)\n",
        "\n",
        "    # Now you have a DataFrame with 'Region' column\n",
        "    print(mp_inquiries_df_part1.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "ifPZr0MaQitf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Region Categorization\n",
        "Region Categorization (Part 2):\n",
        "Define a function (map_constituency_to_region) to categorize constituencies into regions based on a flexible approach.\n",
        "Apply the mapping function to create a new 'Region' column in the DataFrame."
      ],
      "metadata": {
        "id": "cjyzoUfRPvE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataFrame 'mp_inquiries_df_part1' if it doesn't exist\n",
        "if 'mp_inquiries_df_part1' not in globals():\n",
        "    # Load the data into the DataFrame\n",
        "    mp_inquiries_df_part1 = pd.DataFrame({'Constituency': ['Edinburgh South', 'Belfast East', 'Manchester Central']})\n",
        "\n",
        "# Define a function to map constituencies to regions\n",
        "def map_constituency_to_region(constituency):\n",
        "\n",
        "    # For illustration, we'll assume a direct mapping\n",
        "    if \"Scotland\" in constituency:\n",
        "        return \"Scotland\"\n",
        "    elif \"Northern Ireland\" in constituency:\n",
        "        return \"Northern Ireland\"\n",
        "    else:\n",
        "        return \"England\"  # Default to England\n",
        "\n",
        "# Apply the mapping function to create a 'Region' column\n",
        "mp_inquiries_df_part1['Region'] = mp_inquiries_df_part1['Constituency'].apply(map_constituency_to_region)\n",
        "\n",
        "# Now you have a DataFrame with a 'Region' column\n",
        "print(mp_inquiries_df_part1.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "6WzxQByPZB_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: LDA Topic Modeling\n",
        "LDA Topic Modeling (Part 2):\n",
        "Utilize scikit-learn to perform Latent Dirichlet Allocation (LDA) topic modeling on the inquiries' text data.\n",
        "Preprocess the text data using a basic CountVectorizer.\n",
        "Display the top words for each topic identified by LDA."
      ],
      "metadata": {
        "id": "pMFs_GojPpQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mp_inquiries_df_part1.columns\n",
        "\n",
        "# Use a basic CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "inquiry_text_matrix = vectorizer.fit_transform(mp_inquiries_df_part1['Constituency'])\n",
        "\n",
        "# Apply LDA\n",
        "num_topics = 5  # You can adjust the number of topics based on your analysis\n",
        "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "lda.fit(inquiry_text_matrix)\n",
        "\n",
        "# Display the top words for each topic\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
        "    print(f\"Topic #{topic_idx + 1}: {', '.join(top_words)}\")\n"
      ],
      "metadata": {
        "id": "Ccx9qSQvPjCq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}